{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import codecs\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from collections import Counter\n",
    "import scipy\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.metrics.pairwise import pairwise_distances as pdist\n",
    "\n",
    "from scripts.utils import *\n",
    "from scripts.readability_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in_ridero_pos = 'snapshot50/ridero_parsed_json'\n",
    "dir_in_ridero_raw = 'snapshot50/ridero_books'\n",
    "dir_in_ridero_json = 'snapshot50/ridero_json'\n",
    "dir_in_canon_raw = 'txt_cut'\n",
    "dir_in_canon_pos = 'parsed_json_cut'\n",
    "k = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  36,  31,   7, 107])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = pd.read_csv('collection_catalog_full_final.csv', sep=';')\n",
    "with open('stop3grams.txt', 'r') as f:\n",
    "    stop3grams = set([s.lower() for s in f.read().splitlines()])\n",
    "authors = []\n",
    "book_names = []\n",
    "book_fbusta_ids = []\n",
    "book_ids = []\n",
    "for filename in sorted(os.listdir(dir_in_canon_pos)):\n",
    "    with open(os.path.join(dir_in_canon_pos, filename), 'r') as book:\n",
    "        fbusta_id = int(filename.split('.')[0])\n",
    "        book_fbusta_ids.append(fbusta_id)\n",
    "        book_ids.append(get_book_id(fbusta_id, catalog))\n",
    "        authors.append(get_author_id(fbusta_id, catalog))\n",
    "        book_names.append(get_book_name(fbusta_id, catalog))\n",
    "book_fbusta_ids = np.array(book_fbusta_ids)\n",
    "book_names = np.array(book_names)\n",
    "authors = np.array(authors)\n",
    "book_ids = np.array(book_ids)\n",
    "groups = pd.Series(authors).value_counts()\n",
    "singles = np.array(groups[groups==1].index)\n",
    "singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 85.4 ms, total: 2.7 s\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = []\n",
    "lengths = []\n",
    "for filename in sorted(os.listdir(dir_in_canon_raw)):\n",
    "    fbusta_id = int(filename.split('.')[0])\n",
    "    if get_author_id(fbusta_id, catalog) in singles:\n",
    "        continue\n",
    "    with codecs.open(os.path.join(dir_in_canon_raw, filename), encoding='utf-8') as book:\n",
    "        content = book.read()\n",
    "        data.append(content)\n",
    "        lengths.append(len(re.findall(u\"(?u)\\\\b\\\\w+\\\\b\", content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array(data)\n",
    "len_train = np.array(lengths)\n",
    "authors_train = authors\n",
    "train_idx = np.array(range(len(authors)))\n",
    "test_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 69.4 ms, total: 10.4 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_mfw = CountVectorizer(max_features=k, token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\").fit(data_train)\n",
    "td = pd.DataFrame(cv_mfw.transform(data_train).todense())\n",
    "td.columns = sorted(cv_mfw.vocabulary_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = td.div(len_train, axis=0)\n",
    "sclr = StandardScaler().fit(freqs)\n",
    "freqs_sc = sclr.transform(freqs)\n",
    "cosine_delta = pd.DataFrame(pdist(freqs_sc, metric='cosine'))\n",
    "b_delta = pd.DataFrame(pdist(freqs_sc, metric='manhattan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridero_catalog = pd.read_csv('ridero_catalog', sep=';')\n",
    "ridero_catalog.columns = ['filename', 'author', 'bookname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Алиса Чалис'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridero_catalog[ridero_catalog['filename'] == 'addikt']['author'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridero delta\n",
    "ridero_data = []\n",
    "ridero_lengths = []\n",
    "ridero_authors = []\n",
    "ridero_filenames = []\n",
    "ridero_booknames = []\n",
    "for filename in sorted(os.listdir(dir_in_ridero_raw)):\n",
    "    if not os.path.isfile(os.path.join(dir_in_ridero_raw, filename)):\n",
    "        continue\n",
    "    with codecs.open(os.path.join(dir_in_ridero_raw, filename), encoding='utf-8') as book:\n",
    "        content = book.read()\n",
    "        ridero_filenames.append(filename)\n",
    "        author = ridero_catalog[ridero_catalog['filename'] == filename]['author'].item()\n",
    "        bookname = ridero_catalog[ridero_catalog['filename'] == filename]['bookname'].item()\n",
    "        ridero_authors.append(author)\n",
    "        ridero_booknames.append(bookname.replace('\\xa0', ' '))\n",
    "        ridero_data.append(content)\n",
    "        ridero_lengths.append(len(re.findall(u\"(?u)\\\\b\\\\w+\\\\b\", content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Рубина'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog[catalog['author_id'] == 111]['author_surname'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridero_data = np.array(ridero_data)\n",
    "ridero_lengths = np.array(ridero_lengths)\n",
    "ridero_authors = np.array(ridero_authors)\n",
    "ridero_filenames = np.array(ridero_filenames)\n",
    "ridero_booknames = np.array(ridero_booknames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtd = pd.DataFrame(cv_mfw.transform(ridero_data).todense())\n",
    "rtd.columns = sorted(cv_mfw.vocabulary_)\n",
    "freqs_ridero = rtd.div(ridero_lengths, axis=0)\n",
    "freqs_ridero_sc = sclr.transform(freqs_ridero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = scipy.spatial.distance.cdist(freqs_ridero_sc, freqs_sc, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i, ridero_book in enumerate(dists):\n",
    "    closest = dists[i].argsort()[:5]\n",
    "    for j in closest:\n",
    "        canon_a = catalog[catalog['author_id'] == authors[j]]['author_surname'].iloc[0]\n",
    "        res.append((\n",
    "            ridero_filenames[i],\n",
    "            ridero_booknames[i],\n",
    "            ridero_authors[i],\n",
    "            canon_a,\n",
    "            book_names[j],\n",
    "            book_fbusta_ids[j],\n",
    "            dists[i][j]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res).to_csv('snapshot50/cos_delta_top5.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest = dists[0].argsort()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30 вещей, которые каждая девушка должна успеть сделать до 30 лет',\n",
       "       'Боги Олимпа', 'Черникина и другие', '69 +/– 1 = Ad hoc',\n",
       "       'Амур де труа'], dtype='<U64')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ridero_booknames)[closest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dop = []\n",
    "for i, u in enumerate(freqs_ridero_sc):\n",
    "    for j,v in enumerate(freqs_sc):\n",
    "        dop.append((ridero_names[i], whole[j], 1 - scipy.spatial.distance.cosine(freqs_sc[j], freqs_ridero_sc[i]), 'undirected'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
