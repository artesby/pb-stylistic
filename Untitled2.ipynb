{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = 'txt_cut'\n",
    "train = []\n",
    "for filename in sorted(os.listdir(dir_in)):\n",
    "    with open(os.path.join(dir_in, filename), 'r') as book:\n",
    "        train.append(book.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = pd.Series(train).str.split(expand=True).unstack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'go' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6c612f1fb386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = [go.Bar(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             marker= dict(colorscale='Jet',\n\u001b[1;32m      5\u001b[0m                          \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'go' is not defined"
     ]
    }
   ],
   "source": [
    "data = [go.Bar(\n",
    "            x = all_words.index.values[:50],\n",
    "            y = all_words.values[:50],\n",
    "            marker= dict(colorscale='Jet',\n",
    "                         color = all_words.values[:100]\n",
    "                        ),    \n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Top 50 (Uncleaned) Word frequencies in the training dataset',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 621/621 [00:58<00:00, 12.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "dir_in = 'json_cut'\n",
    "train = []\n",
    "for filename in tqdm(sorted(os.listdir(dir_in))):\n",
    "    with open(os.path.join(dir_in, filename), 'r') as book:\n",
    "        content = book.read()\n",
    "        lines = [json.loads(l) for l in content.splitlines()]\n",
    "        txt=[]\n",
    "        for line in lines:\n",
    "            if 'analysis' not in line:\n",
    "                continue\n",
    "            if not line['analysis']:\n",
    "                continue\n",
    "            if 'lex' not in line['analysis'][0]:\n",
    "                continue\n",
    "            txt.append(line['analysis'][0]['lex'])\n",
    "        train.append(' '.join(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.misc import imread\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=2, max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cv.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x49201 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2890 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(max_iter=1,\n",
    "                                learning_method = 'batch',\n",
    "                                random_state = 17,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=1, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=17, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'topic_word_prior': [1, 0.1, 0.01, 0.001],\n",
    "    'n_components': [20, 40, 60],\n",
    "    'doc_topic_prior': [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "model = GridSearchCV(lda, param_grid=params, n_jobs=4, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 1 1 perplexity= 9470.213832620531\n",
      "40 1 1 perplexity= 9730.58910622569\n",
      "60 1 1 perplexity= 9959.24769963195\n",
      "20 1 0.1 perplexity= 9292.719680753984\n",
      "40 1 0.1 perplexity= 9389.887995599804\n",
      "60 1 0.1 perplexity= 9437.91470417996\n",
      "20 1 0.01 perplexity= 9272.881091502251\n",
      "40 1 0.01 perplexity= 9344.664575070105\n",
      "60 1 0.01 perplexity= 9364.79597346844\n",
      "20 1 0.001 perplexity= 9276.462398416073\n",
      "40 1 0.001 perplexity= 9345.049419366956\n",
      "60 1 0.001 perplexity= 9360.945048031941\n",
      "20 0.1 1 perplexity= 8794.812755317493\n",
      "40 0.1 1 perplexity= 8973.74558968059\n",
      "60 0.1 1 perplexity= 9081.8101420611\n",
      "20 0.1 0.1 perplexity= 8696.108903145452\n",
      "40 0.1 0.1 perplexity= 8714.187116619183\n",
      "60 0.1 0.1 perplexity= 8651.237034164422\n",
      "20 0.1 0.01 perplexity= 8693.158066188922\n",
      "40 0.1 0.01 perplexity= 8693.345812661584\n",
      "60 0.1 0.01 perplexity= 8608.38390812501\n",
      "20 0.1 0.001 perplexity= 8708.452392310017\n",
      "40 0.1 0.001 perplexity= 8707.425304464405\n",
      "60 0.1 0.001 perplexity= 8621.806067006513\n",
      "20 0.01 1 perplexity= 9200.537397459328\n",
      "40 0.01 1 perplexity= 9252.969971853749\n",
      "60 0.01 1 perplexity= 9382.9793699354\n",
      "20 0.01 0.1 perplexity= 9236.687696426796\n",
      "40 0.01 0.1 perplexity= 9160.33143717938\n",
      "60 0.01 0.1 perplexity= 9197.405938861903\n",
      "20 0.01 0.01 perplexity= 9249.148305338958\n",
      "40 0.01 0.01 perplexity= 9166.722985068833\n",
      "60 0.01 0.01 perplexity= 9193.964398219649\n",
      "20 0.01 0.001 perplexity= 9275.448827761003\n",
      "40 0.01 0.001 perplexity= 9199.400815364263\n",
      "60 0.01 0.001 perplexity= 9233.91316064919\n",
      "20 0.001 1 perplexity= 10358.73787189617\n",
      "40 0.001 1 perplexity= 10438.240052529703\n",
      "60 0.001 1 perplexity= 10561.403774005843\n",
      "20 0.001 0.1 perplexity= 10477.632312368083\n",
      "40 0.001 0.1 perplexity= 10517.72229955306\n",
      "60 0.001 0.1 perplexity= 10683.813768671343\n",
      "20 0.001 0.01 perplexity= 10509.175280832256\n",
      "40 0.001 0.01 perplexity= 10549.385499406902\n",
      "60 0.001 0.01 perplexity= 10719.023416800143\n",
      "20 0.001 0.001 perplexity= 10543.945208261743\n",
      "40 0.001 0.001 perplexity= 10596.753203690323\n",
      "60 0.001 0.001 perplexity= 10783.472113498572\n",
      "CPU times: user 11h 11min 57s, sys: 5min 36s, total: 11h 17min 34s\n",
      "Wall time: 2h 49min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for t in [1, 0.1, 0.01, 0.001]:\n",
    "    for d in [1, 0.1, 0.01, 0.001]:\n",
    "        for n in [20, 40, 60]:\n",
    "            lda = LatentDirichletAllocation(\n",
    "                topic_word_prior=t,\n",
    "                doc_topic_prior=d,\n",
    "                n_components=n,\n",
    "                max_iter=50,\n",
    "                learning_method = 'batch',\n",
    "                random_state = 17,\n",
    "            )\n",
    "            lda.fit(train)\n",
    "            print(n, t, d, 'perplexity=', lda.perplexity(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print top words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        print(message)\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<621x49201 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1382939 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "\n",
      "Topic #0:художник захар лось григорий павлович гек чук мать абрамович станция\n",
      "======================================================================\n",
      "\n",
      "Topic #1:шубин елена назарыч степанович завод доктор берсенев площадь лев толстяк\n",
      "======================================================================\n",
      "\n",
      "Topic #2:любить друг ваш сердце потому отец молодой казаться мать несколько\n",
      "======================================================================\n",
      "\n",
      "Topic #3:василий кузнецов зоя юлия вагон снег бессонов товарищ лейтенант нечаев\n",
      "======================================================================\n",
      "\n",
      "Topic #4:андрей петька доктор филиппов люба лазик захарка виктор левша мальчишка\n",
      "======================================================================\n",
      "\n",
      "Topic #5:король митя принц ну принцесса министр колпак невидимка вильгельм ваш\n",
      "======================================================================\n",
      "\n",
      "Topic #6:егор артем лева кролик иванович ну ленька удав монах ваня\n",
      "======================================================================\n",
      "\n",
      "Topic #7:земля черный белый ночь вода лес дорога небо солнце гора\n",
      "======================================================================\n",
      "\n",
      "Topic #8:сережа мишка львовна яйцо ну инкубатор цыпленок ребята буба ведь\n",
      "======================================================================\n",
      "\n",
      "Topic #9:глеб фомич машина живой город рубчик дед братик генерал кудрявцев\n",
      "======================================================================\n",
      "\n",
      "Topic #10:алеша маша кот васька волшебник дмитриевич иван валька дядя капитан\n",
      "======================================================================\n",
      "\n",
      "Topic #11:степан настасья танюшка барин шкатулка камень ко вовсе женщина конечно\n",
      "======================================================================\n",
      "\n",
      "Topic #12:незнайка знайка гошка зорин ну коротышка лизка шар кнопочка луна\n",
      "======================================================================\n",
      "\n",
      "Topic #13:мама отец папа мальчик бабушка девочка ребенок дед школа тетя\n",
      "======================================================================\n",
      "\n",
      "Topic #14:море берег корабль петя вода капитан пароход палуба павка лодка\n",
      "======================================================================\n",
      "\n",
      "Topic #15:федька андрей лужин надзиратель заключенный курымушка лагерь лагерный беглец побег\n",
      "======================================================================\n",
      "\n",
      "Topic #16:таня саша маруся лосев картина иваныч федор надя павел семенович\n",
      "======================================================================\n",
      "\n",
      "Topic #17:макар мельник уж ивановский ведь потому ковалев таки ну хоть\n",
      "======================================================================\n",
      "\n",
      "Topic #18:солдат война немец лейтенант командир капитан офицер товарищ генерал немецкий\n",
      "======================================================================\n",
      "\n",
      "Topic #19:марина костенко беня старик ильин матрена женя парень левка алексеевич\n",
      "======================================================================\n",
      "\n",
      "Topic #20:крылов голицын ричард бочкарев лаборатория матвеев гроза работать начальник старик\n",
      "======================================================================\n",
      "\n",
      "Topic #21:ну уж иван надо мужик опять отец тоже лошадь мать\n",
      "======================================================================\n",
      "\n",
      "Topic #22:надо ну тоже потому сейчас почему просто ведь про сразу\n",
      "======================================================================\n",
      "\n",
      "Topic #23:нина бим александровна ржевский девочка антонов ниночка анна иван класс\n",
      "======================================================================\n",
      "\n",
      "Topic #24:мир их русский иметь именно более ваш лишь между конец\n",
      "======================================================================\n",
      "\n",
      "Topic #25:алексей иуда григорьевич император генерал народ авдеевич сова иисус париж\n",
      "======================================================================\n",
      "\n",
      "Topic #26:оскар писатель нью надя наташка америка йорк американский елисавета петр\n",
      "======================================================================\n",
      "\n",
      "Topic #27:николай ильич город иванович сергей стол иван комната ну окно\n",
      "======================================================================\n",
      "\n",
      "Topic #28:ну дверь окно комната сейчас стол увидеть стена опять надо\n",
      "======================================================================\n",
      "\n",
      "Topic #29:миша отец генка филипп невеста петрович степаныч пес карп жених\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = cv.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr[0].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(distr[0] > 1e-3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8861.886568944414"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.perplexity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25446587.941832397"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.score(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
